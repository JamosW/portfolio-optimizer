{
  "cells": [
    {
      "cell_type": "raw",
      "id": "1415c1b7",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Untitled\"\n",
        "format: html\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06f5bdbf",
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yahooquery as yq\n",
        "from itertools import permutations\n",
        "\n",
        "\n",
        "#source - Kolari and Pynnonen\n",
        "#returns simulated\n",
        "#r1 = [7, 13, 8, 16, 17]\n",
        "#r2 = [7, 8, 5, 3, 10]\n",
        "r1 = [1.1, 1.7, 2.1, 1.4, 0.2]\n",
        "r2 = [3, 4.2, 4.9, 4.1, 2.5]\n",
        "#get the means\n",
        "mean_r1, mean_r2 = [sum(i)/len(i) for i in [r1, r2]]\n",
        "\n",
        "#divide each value in realized returns from the mean method #1 to get variance\n",
        "var_r1, var_r2 = map(lambda x,y: sum([(x - i)**2 for i in y])/(len(y) - 1), [mean_r1, mean_r2], [r1, r2])\n",
        "\n",
        "#method2 uses more numpy but is slower\n",
        "var_r1, var_r2 = [np.sum(np.square(x- y))/(len(y) - 1) for x,y in zip([mean_r1, mean_r2], [r1, r2])]\n",
        "\n",
        "#get the standard deviation value\n",
        "std_r1, std_r2 = [np.sqrt(i) for i in [var_r1, var_r2]]\n",
        "\n",
        "#first weight column, convert to numpy for vectorized operations\n",
        "weight1 = np.array([i / 10 for i in range(0,11,1)])\n",
        "\n",
        "#second weight column\n",
        "weight2 = np.array(list(reversed(weight1)))\n",
        "\n",
        "#errors calculated by subtracticting each value from mean\n",
        "errors_r1, errors_r2 = list(map(lambda x,y: [i-x for i in y], [mean_r1, mean_r2], [r1, r2]))\n",
        "\n",
        "#product of errors\n",
        "error_prod = [x*y for x,y in zip(errors_r1, errors_r2)]\n",
        "\n",
        "#sum of square errors, used in the variance forumula\n",
        "sserrors_r1, sserrors_r2 = list(map(lambda errors: sum([error**2 for error in errors]), [errors_r1, errors_r2]))\n",
        "\n",
        "#covariance or r1 and r2, the sum of the product of the errors divided by n-1\n",
        "cov = (sum(error_prod)/4)\n",
        "\n",
        "#correlation of r1 and r2\n",
        "corr = sum(error_prod)/np.sqrt(sserrors_r1 * sserrors_r2)\n",
        "#or more simply\n",
        "corr = cov/(std_r1 * std_r2)\n",
        "\n",
        "#portfolio weighted returns\n",
        "rp = np.add(*[x*y for x,y in zip([weight1, weight2], [mean_r1, mean_r2])])\n",
        "\n",
        "#df structure, will change to an array\n",
        "mydf = pd.DataFrame({\"w1\": weight1, \"w2\": weight2,\n",
        "                     \"R1\": mean_r1, \"R2\" : mean_r2,\n",
        "                     \"Rp\": rp,\n",
        "                     \"stdR1\": std_r1, \"stdR2\": std_r2,\n",
        "                     \"cov\": cov})\n",
        "\n",
        "mydf\n",
        "\n",
        "#minimum variance portfolio (to do)\n",
        "w1 = (std_r2**2 - cov) / (std_r1**2  + std_r2**2 - (2 * cov))\n",
        "\n",
        "#general portfolio variance formula\n",
        "my_var = (weight1**2 * std_r1**2) + (weight2**2 * std_r2**2) + (2 * weight1 * weight2 * cov)\n",
        "\n",
        "#creating a general plot, using portfolio standard deviation std and return lists\n",
        "dat = pd.DataFrame({\"std\": np.sqrt(stds), \"rets\" : rp})\n",
        "\n",
        "#three stock portfolio\n",
        "#get the variance and weight of each and then add the combinations\n",
        "#best to grab from a list\n",
        "\n",
        "    \n",
        "#get the data\n",
        "#get the data\n",
        "df2 = yq.Ticker([ \"AMZN\", \"MMM\"], asynchronous = True).history(period = \"10y\", interval=\"3mo\", start = \"2012-06-01\")\n",
        "\n",
        "def stock_returns() -> [pd.Series]:\n",
        "    dfs = []\n",
        "    for mf in [df2.loc[[i]] for i in np.unique(df2.index.get_level_values(0))]:\n",
        "        #return all values from first month of year (every 4 months)\n",
        "        close = np.array(mf.iloc[[i in range(0,mf.shape[0], 4) for i in range(0,mf.shape[0], 1)], :].close)\n",
        "        #get returns in percentage\n",
        "        ret = (close[1:]/close[:-1]) - 1\n",
        "        dfs.append(ret)\n",
        "    return dfs\n",
        "\n",
        "df = stock_returns()\n",
        "\n",
        "def get_params(rets):\n",
        "    means = [i.mean() for i in rets]\n",
        "    errors_list = [(ret - mean) for mean,ret in zip(means, rets)]\n",
        "    squared_errors = [errors**2 for errors in errors_list]\n",
        "    variances = [sum(sq_error)/(len(sq_error) - 1) for mean,sq_error in zip(means, squared_errors)]\n",
        "    #might not need this\n",
        "    standard_dev = np.sqrt(variances)\n",
        "\n",
        "    return {\"variances\": variances, \"std_dev\": standard_dev, \"mean\": means, \n",
        "    \"sq_errors\": squared_errors, \"errors\" : errors_list}\n",
        "\n",
        "params = get_params(df)\n",
        "\n",
        "pkl_index_value = zip(range(2, 7, 1), [i+\".pkl\" for i in [\"two\", \"three\", \"four\", \"five\", \"six\"]])\n",
        "\n",
        "#permutations, filter out the ones that don't equal 1 and\n",
        "def filter_combo_write_pkl(n_combos: int, filename: str):\n",
        "    weights = [i/100 for i in range(0, 101, 5)]\n",
        "    combos = permutations(weights, n_combos)\n",
        "    filters = pd.DataFrame(filter(lambda x: sum(x) == 1, combos))\n",
        "\n",
        "    #convert to pickle\n",
        "    filters.to_pickle(filename)\n",
        "\n",
        "\n",
        "#write to csv   \n",
        "for index, names in pkl_index_value:\n",
        "    filter_combo_write_pkl(index, names)\n",
        "\n",
        "\n",
        "\n",
        "def portfolio_variance(pkl_file, limit, params):\n",
        "    param = [param[:limit] for param in params.values()]\n",
        "    \n",
        "    #sum of squared errors\n",
        "    sserror = [sum(i) for i in param[3]]\n",
        "    #weights\n",
        "    weights = pd.read_pickle(pkl_file)\n",
        "    #variance\n",
        "    var = np.array(param[0])\n",
        "    std = np.sqrt(var)\n",
        "    #sum prod / sqrt(sq_error1 * sq_error2)\n",
        "    cor = sum(list(map(lambda *error: np.prod(error), *param[4])))/np.sqrt(np.array(sserror).prod())\n",
        "   \n",
        "    w_a = weights**2 * var\n",
        "    return cor\n",
        "\n",
        "#next step correlation\n",
        "#perhaps use a switch stagement for the csv file\n",
        "portfolio_variance(\"two.csv\", 2).sum(axis = 1) + (2 * wts.prod(axis = 1)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
